{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "from train import clean_data\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n",
        "import pickle\r\n",
        "import joblib\r\n",
        "\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1609226213655
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#ws = Workspace.from_config()\n",
        "ws = Workspace.get(name=\"quick-starts-ws-132278\")\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'automl'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code EPBLAT9PM to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Interactive authentication successfully completed.\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1609226243318
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Create compute cluster\r\n",
        "\r\n",
        "cluster_name = \"cpu-cluster\"\r\n",
        "try:\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing compute target')\r\n",
        "except ComputeTargetException:\r\n",
        "    print('Creating a new compute target...')\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \r\n",
        "                                                           max_nodes=4)\r\n",
        "\r\n",
        "    # create the cluster\r\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "\r\n",
        "# can poll for a minimum number of nodes and for a specific timeout. \r\n",
        "# if no min node count is provided it uses the scale settings for the cluster\r\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\r\n",
        "\r\n",
        "# use get_status() to get a detailed status for the current cluster. \r\n",
        "print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a new compute target...\n",
            "Creating\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n",
            "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-12-29T07:17:45.577000+00:00', 'errors': None, 'creationTime': '2020-12-29T07:17:39.567563+00:00', 'modifiedTime': '2020-12-29T07:17:55.643850+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609226280593
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dataset\r\n",
        "key = \"Titanic\"\r\n",
        "description_text = \"Titanic survival dataset\"\r\n",
        "if key in ws.datasets.keys(): \r\n",
        "    print(\"Found registered dataset\")\r\n",
        "    ds = ws.datasets[key] \r\n",
        "else:\r\n",
        "    print(\"Cannot find registered dataset\")\r\n",
        "    \r\n",
        "df = ds.to_pandas_dataframe()\r\n",
        "print(df.shape)\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found registered dataset\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609226291058
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the clean_data function to clean your data.\r\n",
        "label = \"Survived\"\r\n",
        "data, y = clean_data(ds)\r\n",
        "data[label] = y  # Add label column into data\r\n",
        "print(data.shape)\r\n",
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Survived\n0       3    0  22.0      1      0   7.2500         2         0\n1       1    0  38.0      1      0  71.2833         0         1\n2       3    0  26.0      0      0   7.9250         2         1\n3       1    0  35.0      1      0  53.1000         2         1\n4       3    0  35.0      0      0   8.0500         2         0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609227869916
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the train data to a csv to be uploaded to the datastore\r\n",
        "if not os.path.isdir('data'):\r\n",
        "    os.mkdir('data')    \r\n",
        "pd.DataFrame(data).to_csv(\"data/train_data.csv\", index=False)\r\n",
        "ds = ws.get_default_datastore()\r\n",
        "ds.upload(src_dir='./data', target_path='Titanic', overwrite=True, show_progress=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the training data as a tabular dataset for access during training on remote compute\r\n",
        "# automl doesnt accept dataframe or csv \r\n",
        "train_data = Dataset.Tabular.from_delimited_files(path=ds.path('Titanic/train_data.csv'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\r\n",
        "# Set parameters for AutoMLConfig\r\n",
        "automl_settings = {\r\n",
        "    \"enable_early_stopping\" : True,\r\n",
        "    \"iteration_timeout_minutes\": 5,\r\n",
        "    \"max_concurrent_iterations\": 4,\r\n",
        "    \"featurization\": 'auto',\r\n",
        "    \"verbosity\": logging.INFO,\r\n",
        "}\r\n",
        "\r\n",
        "# TODO: Put your automl config here\r\n",
        "automl_config = AutoMLConfig(\r\n",
        "    experiment_timeout_minutes=20,\r\n",
        "    task='classification',\r\n",
        "    compute_target=compute_target,\r\n",
        "    debug_log = 'automl_errors.log',\r\n",
        "    primary_metric='accuracy',\r\n",
        "    training_data=train_data,\r\n",
        "    label_column_name=label,\r\n",
        "    n_cross_validations=5,\r\n",
        "    **automl_settings)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431107951
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(remote_run).show()\r\n",
        "remote_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431121770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert(remote_run.get_status() == \"Completed\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\r\n",
        "\r\n",
        "### YOUR CODE HERE ###\r\n",
        "best_run, fitted_model = remote_run.get_output()\r\n",
        "\r\n",
        "print(best_run)\r\n",
        "print(fitted_model)\r\n",
        "print(best_run.properties)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\r\n",
        "best_run.download_file('outputs/model.pkl', 'outputs/model.pkl')\r\n",
        "#best_run.download_file('automl_driver.py', 'outputs/automl_driver.py')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on val set\r\n",
        "key = \"Titanic\"\r\n",
        "description_text = \"Titanic survival dataset\"\r\n",
        "if key in ws.datasets.keys(): \r\n",
        "    print(\"Found registered dataset\")\r\n",
        "    ds = ws.datasets[key] \r\n",
        "else:\r\n",
        "    print(\"Cannot find registered dataset\")\r\n",
        "\r\n",
        "x, y = clean_data(ds)\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\r\n",
        "model_file = open('outputs/model.pkl', 'rb')\r\n",
        "model = pickle.load(model_file)\r\n",
        "model_file.close()\r\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(x_test)))\r\n",
        "print(\"Classification report:\")\r\n",
        "print(classification_report(y_test, model.predict(x_test)))\r\n",
        "print(\"Confusion matrix:\")\r\n",
        "print(confusion_matrix(y_test, model.predict(x_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = remote_run.register_model(description='automl', tags= {'area': 'titanic'})\r\n",
        "print(remote_run.model_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}